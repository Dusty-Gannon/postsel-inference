
## Introduction

Model selection, in some form or another, is commonplace in ecological data analysis. The motivation for considering and fitting multiple models to data varies [see @tredennick_2021 for a good discussion] and may include testing multiple hypotheses [e.g., @betts_eco-apps_2006; @burnham_aic_2011; @torresvanegas_joe_2020], identifying a predictive model [e.g., @gerber_lasso_2020; @costa-neto_predict_2021], or exploratory statistical learning and generation of new hypotheses [e.g., @parchman_gwas_2012; @band_gwas_2015]. While model selection in these contexts can be profoundly useful to advancing ecological understanding, it is also common for researchers to want to draw inference on the effects of the variables included in a model that was defined only after conducting model selection. Post-model selection inference (hereafter *post-selection inference*), however, can lead to biased effect estimates, overly confident interval estimates, and exaggerated $p$ values if the construction of these statistics does not account for the selection process itself [@kuchibhotla_post-selection_2022].

Valid post-selection inference is an active area of statistical research [see, for example, @taylor_select-infer_2015; @kuchibhotla_post-selection_2022], meaning there are few general recommendations from statisticians on how to proceed with the goal of inference when some degree of model selection is nearly inherent to the process of analyzing the data we collect. However, simple procedures with clean theoretical results have recently been developed for the specific case of drawing inference on relatively few variables of primary interest while selecting among potentially high-dimensional sets of control variables [@belloni_dsel_2014]. As a concrete example in ecology, consider a field-based experiment designed to test the effect of nutrient addition on the reproductive output of a focal plant species. Nutrient addition is the explanatory variable of interest, but we can postulate many potential environmental factors that could also influence reproduction (e.g., soil type, neighborhood density, neighborhood species composition, plant genotype, etc.), many of which we may not be able to control or randomly assign to experimental units in a field-based experiment. Furthermore, it can be argued that inference drawn from experiments designed to standardize or control these additional environmental factors may not generalize well to natural systems [@currie_newton_2019]. It is therefore useful to include additional covariates (explanatory variables) in a statistical model to gain better resolution on the treatment effect of interest -- at least up to a point. Data are always finite, so the more parameters that are estimated using the same data, the greater the uncertainty in those estimates. Because our interest is in estimating one or a few specific effects with precision (or testing null hypotheses with high power), it is often the goal to include variables that explain substantial variation in the response while maintaining a parsimonious model (i.e., Occam's razor). Unfortunately, how we choose the control variables can impact inference on the focal effects.


